{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identifier           object\n",
       "company_name_norm    object\n",
       "country_code         object\n",
       "phone_parsed         object\n",
       "domain               object\n",
       "city                 object\n",
       "zip_code             object\n",
       "category             object\n",
       "address              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df=pd.read_parquet('../../datasets/working/full_df.parquet')\n",
    "\n",
    "fb_norm_df=pd.read_parquet('../../datasets/working/fb_norm.parquet')\n",
    "g_norm_df=pd.read_parquet('../../datasets/working/g_norm.parquet')\n",
    "w_norm_df=pd.read_parquet('../../datasets/working/w_norm.parquet')\n",
    "\n",
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_domains = g_norm_df['domain'].value_counts()\n",
    "facebook_domains = fb_norm_df['domain'].value_counts()\n",
    "websites_domains = w_norm_df['domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_patterns = [\n",
    "    r\"(?i).*facebook\\.com$\",   # Facebook\n",
    "    r\"(?i).*twitter\\.com$\",    # Twitter\n",
    "    r\"(?i).*instagram\\.com$\",  # Instagram\n",
    "    ]\n",
    "\n",
    "def is_social_media_domain(domain):\n",
    "    if pd.isnull(domain):\n",
    "        return np.nan\n",
    "    elif isinstance(domain, str):\n",
    "        for pattern in social_media_patterns:\n",
    "            if regex.match(pattern, domain):\n",
    "                return 'Y'\n",
    "        return 'N'\n",
    "    else:\n",
    "        return domain\n",
    "    \n",
    "def calculate_company_name_fuzzy_score(row):\n",
    "    company_name_x = str(row['company_name_norm_x'])  # Convert to string\n",
    "    company_name_y = str(row['company_name_norm_y'])  # Convert to string\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if company_name_x == 'nan' or company_name_y == 'nan':\n",
    "        return 0\n",
    "    \n",
    "    return fuzz.ratio(company_name_x, company_name_y)\n",
    "\n",
    "def check_category_inclusion(row):\n",
    "    result = np.nan\n",
    "    category_x = str(row['category_x']) # Convert to string\n",
    "    category_y = str(row['category_y']) # Convert to string\n",
    "    if (category_x == 'nan' and category_y == 'nan') or (category_x != 'nan' and category_y == 'nan'):\n",
    "        result = 0\n",
    "    else:\n",
    "        if category_x == 'nan' and category_y != 'nan':\n",
    "            result = 1\n",
    "        else:\n",
    "            if category_y in category_x:\n",
    "                result = 0\n",
    "            else:\n",
    "                result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['social_media_flag'] = full_df['domain'].apply(is_social_media_domain)\n",
    "mask_no_social_media = (full_df['social_media_flag'] == 'N')\n",
    "\n",
    "g_soc_med = full_df[~mask_no_social_media].copy()\n",
    "\n",
    "full_df_no_soc = full_df[mask_no_social_media].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_websites = full_df['identifier'].str.contains('website')\n",
    "mask_google = full_df['identifier'].str.contains('google')\n",
    "mask_facebook = full_df['identifier'].str.contains('facebook')\n",
    "\n",
    "#Getting full_df wihtout websites to enrich it furhter with data in websites\n",
    "\n",
    "no_w = full_df[~mask_websites].merge(w_norm_df, how='left', on=['domain']) #merging on domain as there is a lot of consistency and low missing values\n",
    "no_w.reset_index(drop=True, inplace=True)\n",
    "\n",
    "no_w['name_fuzzy_score'] = no_w.apply(calculate_company_name_fuzzy_score, axis=1)\n",
    "no_w['category_inclusion_flag'] = no_w.apply(check_category_inclusion,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 428484    [100.00 %]\n",
      "Total records no country      :  66543    [ 15.53 %]\n",
      "Total records no domain       :      0    [  0.0  %]\n",
      "Total records no city         :  72387    [ 16.89 %]\n",
      "Total records no zip          : 119046    [ 27.78 %]\n",
      "Total records no phone_parsed :  59804    [ 13.96 %]\n",
      "Total records no category     :  68330    [ 15.95 %]\n",
      "Total records no address      :  40566    [ 9.47 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(no_w)\n",
    "null_country  = len(no_w[no_w['country_code_x'].isnull()])\n",
    "null_domain  = len(no_w[no_w['domain'].isnull()])\n",
    "null_city = len(no_w[no_w['city_x'].isnull()])\n",
    "null_zip = len(no_w[no_w['zip_code_x'].isnull()])\n",
    "null_phones = len(no_w[no_w['phone_parsed_x'].isnull()])\n",
    "null_category = len(no_w[no_w['category_x'].isnull()])\n",
    "null_address = len(no_w[no_w['address_x'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          : {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [ {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [ {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#City Enrichment from Websites\n",
    "no_w['city_enriched'] = np.where(\n",
    "    (no_w['city_x'].isnull() & no_w['city_y'].notnull())\n",
    "    & (\n",
    "      (no_w['company_name_norm_x'] == no_w['company_name_norm_y'])\n",
    "    | ((no_w['name_fuzzy_score']>50) & (no_w['city_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    | ((no_w['company_name_norm_x'] == no_w['company_name_norm_y'] )& (no_w['country_code_x'] == no_w['country_code_y']) & no_w['country_code_x'].notnull())\n",
    "    ),\n",
    "    no_w['city_y'],\n",
    "    None\n",
    ")\n",
    "\n",
    "no_w['city_enriching_id'] = np.where(\n",
    "     (no_w['city_x'].isnull() & no_w['city_y'].notnull())\n",
    "    & (\n",
    "      (no_w['company_name_norm_x'] == no_w['company_name_norm_y'])\n",
    "    | ((no_w['name_fuzzy_score']>50) & (no_w['city_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    | ((no_w['company_name_norm_x'] == no_w['company_name_norm_y'] )& (no_w['country_code_x'] == no_w['country_code_y']) & no_w['country_code_x'].notnull())\n",
    "    ),\n",
    "    no_w['identifier_y'],\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enriched cities : 19149 [ 26.45 %] [ 4.47 %]\n"
     ]
    }
   ],
   "source": [
    "total_enriched = len(no_w[no_w['city_enriching_id'].notnull()])\n",
    "print(f'Total enriched cities : {total_enriched} [ {round((total_enriched/null_city)*100,2)} %] [ {round((total_enriched/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country Enrichment from Websites\n",
    "no_w['country_enriched'] = np.where( \n",
    "      ((no_w['country_code_x'].isnull())) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['country_code_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    ),\n",
    "    no_w['country_code_y'],\n",
    "    None\n",
    ")\n",
    "\n",
    "no_w['country_enriching_id'] = np.where(\n",
    "     ((no_w['country_code_x'].isnull()))\n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['country_code_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    ),\n",
    "    no_w['identifier_y'],\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enriched countries : 19149 [ 18.79 %] [ 2.92 %]\n"
     ]
    }
   ],
   "source": [
    "total_enriched_country = len(no_w[no_w['country_enriching_id'].notnull()])\n",
    "print(f'Total enriched countries : {total_enriched} [ {round((total_enriched_country/null_country)*100,2)} %] [ {round((total_enriched_country/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phone Enrichment from Websites\n",
    "no_w['phone_enriched'] = np.where( \n",
    "      ((no_w['phone_parsed_x'].isnull()) | (no_w['phone_parsed_x']=='nan') ) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['phone_parsed_y'].notnull()))\n",
    "    ),\n",
    "    no_w['phone_parsed_y'],\n",
    "    None\n",
    ")\n",
    "\n",
    "no_w['phone_enriching_id'] = np.where(\n",
    "     ((no_w['phone_parsed_x'].isnull()) | (no_w['phone_parsed_x']=='nan') ) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['phone_parsed_y'].notnull()))\n",
    "    ),\n",
    "    no_w['identifier_y'],\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enriched phones : 19149 [ 16.6 %] [ 2.32 %]\n"
     ]
    }
   ],
   "source": [
    "total_enriched_phones = len(no_w[no_w['phone_enriching_id'].notnull()])\n",
    "print(f'Total enriched phones : {total_enriched} [ {round((total_enriched_phones/null_phones)*100,2)} %] [ {round((total_enriched_phones/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category Enrichment from Websites\n",
    "no_w['category_enriched'] = np.where( \n",
    "      ((no_w['category_inclusion_flag']>0) & (no_w['category_x'].notnull())) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['category_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    ),\n",
    "    no_w['category_x'] + '|' + no_w['category_y'],\n",
    "    np.where(\n",
    "        ((no_w['category_inclusion_flag']>0) & (no_w['category_x'].isnull())) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['category_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    ),\n",
    "    no_w['category_y'],\n",
    "    None\n",
    "    )\n",
    ")\n",
    "\n",
    "no_w['category_enriching_id'] = np.where(\n",
    "     ((no_w['category_inclusion_flag']>0)) \n",
    "    &(\n",
    "      ((no_w['name_fuzzy_score']>50) & (no_w['category_y'].notnull()))\n",
    "    | ((no_w['phone_parsed_x'] == no_w['phone_parsed_y']) & no_w['phone_parsed_x'].notnull())\n",
    "    ),\n",
    "    no_w['identifier_y'],\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enriched categories : 19149 [ 134.55 %] [ 21.46 %]\n"
     ]
    }
   ],
   "source": [
    "total_enriched_categories = len(no_w[no_w['category_enriching_id'].notnull()])\n",
    "print(f'Total enriched categories : {total_enriched} [ {round((total_enriched_categories/null_category)*100,2)} %] [ {round((total_enriched_categories/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_w.to_parquet('../../datasets/working/no_web.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../datasets/working/no_web.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_country = df['country_enriching_id'].notnull() & df['country_code_x'].isnull()\n",
    "mask_phone = df['phone_enriching_id'].notnull() & df['phone_parsed_x'].isnull()\n",
    "mask_city = df['city_enriching_id'].notnull() & df['city_x'].isnull()\n",
    "mask_category = df['category_enriching_id'].notnull() & df['category_x'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[mask_country, 'country_code_x'] = df.loc[mask_country, 'country_enriched'] #14350\n",
    "df.loc[mask_phone, 'phone_parsed_x'] = df.loc[mask_phone, 'phone_enriched'] #14350\n",
    "df.loc[mask_city, 'city_x'] = df.loc[mask_city, 'city_enriched'] #14350\n",
    "df.loc[mask_category, 'category_x'] = df.loc[mask_category, 'category_enriched'] #14350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 428484    [100.00 %]\n",
      "Total records no country      :  54182    [ 12.65 %]\n",
      "Total records no domain       :      0    [  0.0  %]\n",
      "Total records no city         :  53238    [ 12.42 %]\n",
      "Total records no zip          : 119046    [ 27.78 %]\n",
      "Total records no phone_parsed :  49877    [ 11.64 %]\n",
      "Total records no category     :  45838    [ 10.7  %]\n",
      "Total records no address      :  40566    [  9.47 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(df)\n",
    "null_country  = len(df[df['country_code_x'].isnull()])\n",
    "null_domain  = len(df[df['domain'].isnull()])\n",
    "null_city = len(df[df['city_x'].isnull()])\n",
    "null_zip = len(df[df['zip_code_x'].isnull()])\n",
    "null_phones = len(df[df['phone_parsed_x'].isnull()])\n",
    "null_category = len(df[df['category_x'].isnull()])\n",
    "null_address = len(df[df['address_x'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          : {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [ {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)}  %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'city_enriching_id','country_enriching_id','phone_enriching_id','category_enriching_id'\n",
    "mask_changed_rows = df['city_enriching_id'].notnull() | df['country_enriching_id'].notnull() | df['phone_enriching_id'].notnull() | df['category_enriching_id'].notnull()\n",
    "normalised_columns = ['identifier','company_name_norm','other_company_name','country_code','phone_parsed','domain','city','zip_code','category','address','social_media_flag','city_enriching_id','country_enriching_id','phone_enriching_id','category_enriching_id']\n",
    "df.rename(columns={\n",
    "    'identifier_x':'identifier',\n",
    "    'company_name_norm_x': 'company_name_norm',\n",
    "    'country_code_x': 'country_code',\n",
    "    'phone_parsed_x': 'phone_parsed',\n",
    "    'city_x':'city',\n",
    "    'zip_code_x':'zip_code',\n",
    "    'category_x':'category',\n",
    "    'address_x':'address',\n",
    "    'company_name_norm_y':'other_company_name',\n",
    "},inplace=True)\n",
    "no_w_enriched = df[mask_changed_rows][normalised_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_w_enriched.to_parquet('../../datasets/intermediar/1.1/no_w_enriched.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring the updated data back to full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['city_enriching_id'] = None\n",
    "full_df['country_enriching_id'] = None\n",
    "full_df['phone_enriching_id'] = None\n",
    "full_df['category_enriching_id'] = None\n",
    "full_df['other_company_name'] = None\n",
    "\n",
    "full_df['identifier_index'] = full_df['identifier']\n",
    "full_df.set_index('identifier_index', inplace=True)\n",
    "\n",
    "no_w_enriched['identifier_index'] = no_w_enriched['identifier']\n",
    "no_w_enriched.set_index('identifier_index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.update(no_w_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_parquet('../../datasets/output/full_df_web_enriched.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
