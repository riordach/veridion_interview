{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "from fuzzywuzzy import fuzz\n",
    "import phonenumbers\n",
    "import tldextract as tdl\n",
    "import pycountry\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=pd.read_parquet('../../datasets/output/full_df_web_enriched.parquet')\n",
    "\n",
    "fb_norm_df=pd.read_parquet('../../datasets/working/fb_norm.parquet')\n",
    "g_norm_df=pd.read_parquet('../../datasets/working/g_norm.parquet')\n",
    "w_norm_df=pd.read_parquet('../../datasets/working/w_norm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_patterns = [\n",
    "    r\"(?i).*facebook\\.com$\",   # Facebook\n",
    "    r\"(?i).*twitter\\.com$\",    # Twitter\n",
    "    r\"(?i).*instagram\\.com$\",  # Instagram\n",
    "    ]\n",
    "\n",
    "def is_social_media_domain(domain):\n",
    "    if pd.isnull(domain):\n",
    "        return np.nan\n",
    "    elif isinstance(domain, str):\n",
    "        for pattern in social_media_patterns:\n",
    "            if regex.match(pattern, domain):\n",
    "                return 'Y'\n",
    "        return 'N'\n",
    "    else:\n",
    "        return domain\n",
    "\n",
    "def calculate_company_name_fuzzy_score(row, column_x, column_y):\n",
    "    company_name_x = str(row[column_x])  # Convert to string\n",
    "    company_name_y = str(row[column_y])  # Convert to string\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if company_name_x == 'nan' or company_name_y == 'nan':\n",
    "        return 0\n",
    "    \n",
    "    return fuzz.ratio(company_name_x, company_name_y)\n",
    "\n",
    "def check_category_inclusion(row):\n",
    "    result = np.nan\n",
    "    category_x = str(row['category_x']) # Convert to string\n",
    "    category_y = str(row['category_y']) # Convert to string\n",
    "    if (category_x == 'nan' and category_y == 'nan') or (category_x != 'nan' and category_y == 'nan'):\n",
    "        result = 0\n",
    "    else:\n",
    "        if category_x == 'nan' and category_y != 'nan':\n",
    "            result = 1\n",
    "        else:\n",
    "            if category_x in category_y:\n",
    "                result = 0\n",
    "            else:\n",
    "                result = 1\n",
    "    return result\n",
    "\n",
    "def get_country_from_phone(phone_number):\n",
    "    try:\n",
    "        parsed_number = phonenumbers.parse(phone_number, None)\n",
    "        country_code = phonenumbers.region_code_for_number(parsed_number)\n",
    "        # country_name = phonenumbers.region_name_for_number(parsed_number)\n",
    "        return country_code.lower()\n",
    "    except phonenumbers.phonenumberutil.NumberParseException:\n",
    "        return None\n",
    "    \n",
    "def extract_tdl(domain):\n",
    "    pattern = r\"(.*\\.)(.*$)\"\n",
    "    match = regex.search(pattern, domain)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def is_country_code_valid(country_code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        if country:\n",
    "            return country.alpha_2\n",
    "        else:\n",
    "            return None\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def extract_zip_code(row, address_column, country_code_column):\n",
    "    country_code = str(row[country_code_column])\n",
    "    text = str(row[address_column])\n",
    "    pattern = \"\"\n",
    "\n",
    "    if country_code == \"us\":\n",
    "        pattern = r\"(?i)\\b\\d{5}(?:-\\d{4})?\\b\"\n",
    "    elif country_code == \"ca\":\n",
    "        pattern = r\"(?i)\\b[A-Za-z]\\d[A-Za-z] \\d[A-Za-z]\\d\\b\"\n",
    "    elif country_code == \"gb\":\n",
    "        pattern = r\"(?i)\\b(?:[A-Z]{1,2}\\d[A-Z\\d]?|\\d[A-Z\\d]{1,2}) \\d[A-Z]{2}\\b\"\n",
    "    elif country_code == \"uk\":\n",
    "        pattern = r\"(?i)\\b(?:[A-Z]{1,2}\\d[A-Z\\d]?|\\d[A-Z\\d]{1,2}) \\d[A-Z]{2}\\b\"\n",
    "    elif country_code == \"au\":\n",
    "        pattern = r\"(?i)\\b\\d{4}\\b\"\n",
    "    elif country_code == \"tr\":\n",
    "        pattern = r\"(?i)\\b\\d{5}\\b\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    match = regex.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data = pd.read_parquet('../../datasets/working/merged_G_fb.parquet')\n",
    "\n",
    "mask_websites = full_df['identifier'].str.contains('website')\n",
    "mask_google = full_df['identifier'].str.contains('google')\n",
    "mask_facebook = full_df['identifier'].str.contains('facebook')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 500503    [100.00 %]\n",
      "Total records no country      :  62702    [ 12.53 %]\n",
      "Total records no domain       :      1    [  0.0  %]\n",
      "Total records no city         :  64300    [ 12.85 %]\n",
      "Total records no zip          :  191064    [ 38.17 %]\n",
      "Total records no phone_parsed :  61666    [  12.32 %]\n",
      "Total records no category     :  47212    [ 9.43 %]\n",
      "Total records no address      :  112583    [  22.49 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(full_df)\n",
    "null_country  = len(full_df[full_df['country_code'].isnull()])\n",
    "null_domain  = len(full_df[full_df['domain'].isnull()])\n",
    "null_city = len(full_df[full_df['city'].isnull()])\n",
    "null_zip = len(full_df[full_df['zip_code'].isnull()])\n",
    "null_phones = len(full_df[full_df['phone_parsed'].isnull()])\n",
    "null_category = len(full_df[full_df['category'].isnull()])\n",
    "null_address = len(full_df[full_df['address'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          :  {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [  {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_phone_no_country = ((full_df['phone_parsed'].notnull()) & (full_df['country_code'].isnull()))\n",
    "\n",
    "df = full_df[mask_phone_no_country].copy()\n",
    "\n",
    "df['country_code']=df['phone_parsed'].apply(get_country_from_phone)\n",
    "df['country_code'] = df['country_code'].str.lower()\n",
    "\n",
    "full_df.update(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_parquet('../../datasets/output/full_df_web_enriched_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 500503    [100.00 %]\n",
      "Total records no country      :  28296    [ 5.65 %]\n",
      "Total records no domain       :      1    [  0.0  %]\n",
      "Total records no city         :  64300    [ 12.85 %]\n",
      "Total records no zip          :  191064    [ 38.17 %]\n",
      "Total records no phone_parsed :  61666    [  12.32 %]\n",
      "Total records no category     :  47212    [ 9.43 %]\n",
      "Total records no address      :  112583    [  22.49 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(full_df)\n",
    "null_country  = len(full_df[full_df['country_code'].isnull()])\n",
    "null_domain  = len(full_df[full_df['domain'].isnull()])\n",
    "null_city = len(full_df[full_df['city'].isnull()])\n",
    "null_zip = len(full_df[full_df['zip_code'].isnull()])\n",
    "null_phones = len(full_df[full_df['phone_parsed'].isnull()])\n",
    "null_category = len(full_df[full_df['category'].isnull()])\n",
    "null_address = len(full_df[full_df['address'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          :  {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [  {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_address_not_null = ((full_df['country_code'].isnull()) & (full_df['social_media_flag'] == 'N'))\n",
    "\n",
    "missing_address = full_df[mask_address_not_null].copy()\n",
    "\n",
    "missing_address['tdl'] = missing_address['domain'].apply(extract_tdl)\n",
    "missing_address['is_tdl_country'] = missing_address['tdl'].apply(is_country_code_valid)\n",
    "missing_address['country_code'] = np.where(missing_address['is_tdl_country'].notnull(), missing_address['tdl'],None)\n",
    "missing_address.drop(columns=['tdl','is_tdl_country'], axis=1, inplace=True)\n",
    "\n",
    "full_df.update(missing_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 500503    [100.00 %]\n",
      "Total records no country      :  19374    [ 3.87 %]\n",
      "Total records no domain       :      1    [  0.0  %]\n",
      "Total records no city         :  64300    [ 12.85 %]\n",
      "Total records no zip          :  191064    [ 38.17 %]\n",
      "Total records no phone_parsed :  61666    [  12.32 %]\n",
      "Total records no category     :  47212    [ 9.43 %]\n",
      "Total records no address      :  112583    [  22.49 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(full_df)\n",
    "null_country  = len(full_df[full_df['country_code'].isnull()])\n",
    "null_domain  = len(full_df[full_df['domain'].isnull()])\n",
    "null_city = len(full_df[full_df['city'].isnull()])\n",
    "null_zip = len(full_df[full_df['zip_code'].isnull()])\n",
    "null_phones = len(full_df[full_df['phone_parsed'].isnull()])\n",
    "null_category = len(full_df[full_df['category'].isnull()])\n",
    "null_address = len(full_df[full_df['address'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          :  {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [  {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_zip_null = full_df['zip_code'].isnull()\n",
    "countries = full_df[mask_zip_null]['country_code'].value_counts()\n",
    "mask_zip_null = full_df['zip_code'].isnull() & full_df['address'].notnull()\n",
    "missing_zip = full_df[mask_zip_null].copy()\n",
    "missing_zip['zip_code'] = missing_zip.apply(extract_zip_code, address_column='address', country_code_column='country_code', axis=1)\n",
    "\n",
    "\n",
    "full_df.update(missing_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 500503    [100.00 %]\n",
      "Total records no country      :  19374    [ 3.87 %]\n",
      "Total records no domain       :      1    [  0.0  %]\n",
      "Total records no city         :  64300    [ 12.85 %]\n",
      "Total records no zip          :  181168    [ 36.2 %]\n",
      "Total records no phone_parsed :  61666    [  12.32 %]\n",
      "Total records no category     :  47212    [ 9.43 %]\n",
      "Total records no address      :  112583    [  22.49 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(full_df)\n",
    "null_country  = len(full_df[full_df['country_code'].isnull()])\n",
    "null_domain  = len(full_df[full_df['domain'].isnull()])\n",
    "null_city = len(full_df[full_df['city'].isnull()])\n",
    "null_zip = len(full_df[full_df['zip_code'].isnull()])\n",
    "null_phones = len(full_df[full_df['phone_parsed'].isnull()])\n",
    "null_category = len(full_df[full_df['category'].isnull()])\n",
    "null_address = len(full_df[full_df['address'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          :  {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [  {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full DF enrichment with Facebook Data\n",
    "- i will make a inner join on phone, zip_code, country_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_null_on_join = full_df['phone_parsed'].notnull() & full_df['zip_code'].notnull() & full_df['country_code'].notnull()\n",
    "mask_no_null_on_join_fb = fb_norm_df['phone_parsed'].notnull() & fb_norm_df['zip_code'].notnull() & fb_norm_df['country_code'].notnull()\n",
    "enrich_fb = full_df[~mask_facebook & mask_no_null_on_join].merge(fb_norm_df[mask_no_null_on_join_fb], how='inner', on=['phone_parsed','zip_code','country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_company_name_fuzzy_score(row):\n",
    "    company_name_x = str(row['company_name_norm_x'])  # Convert to string\n",
    "    company_name_y = str(row['company_name_norm_y'])  # Convert to string\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if company_name_x == 'nan' or company_name_y == 'nan':\n",
    "        return 0\n",
    "    \n",
    "    return fuzz.ratio(company_name_x, company_name_y)\n",
    "\n",
    "def check_category_inclusion(row):\n",
    "    result = np.nan\n",
    "    category_x = str(row['category_x']) # Convert to string\n",
    "    category_y = str(row['category_y']) # Convert to string\n",
    "    if (category_x == 'nan' and category_y == 'nan') or (category_x != 'nan' and category_y == 'nan'):\n",
    "        result = 0\n",
    "    else:\n",
    "        if category_x == 'nan' and category_y != 'nan':\n",
    "            result = 1\n",
    "        else:\n",
    "            if category_x in category_y:\n",
    "                result = 0\n",
    "            else:\n",
    "                result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_fb['name_fuzzy_score'] = enrich_fb.apply(calculate_company_name_fuzzy_score, axis=1)\n",
    "enrich_fb['category_inclusion_flag'] = enrich_fb.apply(check_category_inclusion,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_fb['domain_x'] = np.where(((enrich_fb['social_media_flag']=='Y') & (enrich_fb['name_fuzzy_score']>50)), enrich_fb['domain_y'], enrich_fb['domain_x'])\n",
    "enrich_fb['domain_enriching_id'] = np.where(((enrich_fb['social_media_flag']=='Y') & (enrich_fb['name_fuzzy_score']>50)), enrich_fb['identifier_y'], None)\n",
    "\n",
    "#Category Enrichment from Websites\n",
    "enrich_fb['category_x'] = np.where( \n",
    "      ((enrich_fb['category_inclusion_flag']>0) & (enrich_fb['category_x'].notnull())) \n",
    "    &(\n",
    "      ((enrich_fb['name_fuzzy_score']>50) & (enrich_fb['category_y'].notnull()))\n",
    "    ),\n",
    "    enrich_fb['category_x'] + '|' + enrich_fb['category_y'],\n",
    "    np.where(\n",
    "        ((enrich_fb['category_inclusion_flag']>0) & (enrich_fb['category_x'].isnull())) \n",
    "    &(\n",
    "      ((enrich_fb['name_fuzzy_score']>50) & (enrich_fb['category_y'].notnull()))\n",
    "    ),\n",
    "    enrich_fb['category_y'],\n",
    "   None\n",
    "    )\n",
    ")\n",
    "\n",
    "enrich_fb['category_enriching_id'] = np.where(\n",
    "     ((enrich_fb['category_inclusion_flag']>0) & (enrich_fb['category_enriching_id'].isnull())) \n",
    "    &(\n",
    "      ((enrich_fb['name_fuzzy_score']>50) & (enrich_fb['category_y'].notnull()))\n",
    "    ),\n",
    "    enrich_fb['identifier_y'],\n",
    "   np.where(\n",
    "        ((enrich_fb['category_inclusion_flag']>0) & (enrich_fb['category_enriching_id'].notnull())) \n",
    "    &(\n",
    "      ((enrich_fb['name_fuzzy_score']>50) & (enrich_fb['category_y'].notnull()))\n",
    "    ),\n",
    "    enrich_fb['category_enriching_id']+ \"|\" + enrich_fb['identifier_y'],\n",
    "    None\n",
    "   )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_fb.rename(columns={\n",
    "    'identifier_x':'identifier',\n",
    "    'company_name_norm_x': 'company_name_norm',\n",
    "    'domain_x':'domain',\n",
    "    'city_x':'city',\n",
    "    'category_x':'category',\n",
    "    'address_x':'address',\n",
    "},inplace=True)\n",
    "\n",
    "enrich_fb['identifier_index'] = enrich_fb['identifier']\n",
    "\n",
    "enrich_fb.set_index('identifier_index',inplace=True)\n",
    "\n",
    "mask_changed_rows =  enrich_fb['category_enriching_id'].notnull() | enrich_fb['domain_enriching_id'].notnull()\n",
    "\n",
    "normalised_columns = ['identifier','company_name_norm','country_code','phone_parsed','domain','city','zip_code','category','address','social_media_flag','city_enriching_id','country_enriching_id','phone_enriching_id','category_enriching_id','other_company_name','domain_enriching_id']\n",
    "\n",
    "df = enrich_fb[mask_changed_rows][normalised_columns]\n",
    "df = df = df[~df.index.duplicated(keep='first')]\n",
    "full_df['domain_enriching_id'] = None\n",
    "\n",
    "full_df.update(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 500503    [100.00 %]\n",
      "Total records no country      :  19374    [ 3.87 %]\n",
      "Total records no domain       :      1    [  0.0  %]\n",
      "Total records no city         :  64300    [ 12.85 %]\n",
      "Total records no zip          :  181168    [ 36.2 %]\n",
      "Total records no phone_parsed :  61666    [  12.32 %]\n",
      "Total records no category     :  47019    [ 9.39 %]\n",
      "Total records no address      :  112583    [  22.49 %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(full_df)\n",
    "null_country  = len(full_df[full_df['country_code'].isnull()])\n",
    "null_domain  = len(full_df[full_df['domain'].isnull()])\n",
    "null_city = len(full_df[full_df['city'].isnull()])\n",
    "null_zip = len(full_df[full_df['zip_code'].isnull()])\n",
    "null_phones = len(full_df[full_df['phone_parsed'].isnull()])\n",
    "null_category = len(full_df[full_df['category'].isnull()])\n",
    "null_address = len(full_df[full_df['address'].isnull()])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :  {null_country}    [ {round((null_country/total_records)*100,2)} %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no city         :  {null_city}    [ {round((null_city/total_records)*100,2)} %]')\n",
    "print(f'Total records no zip          :  {null_zip}    [ {round((null_zip/total_records)*100,2)} %]')\n",
    "print(f'Total records no phone_parsed :  {null_phones}    [  {round((null_phones/total_records)*100,2)} %]')\n",
    "print(f'Total records no category     :  {null_category}    [ {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :  {null_address}    [  {round((null_address/total_records)*100,2)} %]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other enriching data that can be done but due to lack of resources i gave up on implementing it:\n",
    "- similar to the facebook enrichment google enrichemtn should be done.\n",
    "- address parsing should be done on the free text address. This step should have been done prior to the facebook and google enrichment. This will potentially increase the matching.\n",
    "- fuzy matching on combination of the company_name_norm, country, address should be done in order to furhter entich and minimse the duplication of the domain data. an example can be found in the fuzzymatch.py and the merged_G_fb.parquet.\n",
    "- Also a deduplication should be done based on the enriching identifiers, to exclude all the indexed that are found in the enriched columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['combined_column'] = full_df[['city_enriching_id','country_enriching_id','phone_enriching_id','category_enriching_id','domain_enriching_id']].apply(lambda x: '|'.join(x.dropna().astype(str)), axis=1)\n",
    "distinct_df = pd.DataFrame({'unique_values': full_df['combined_column'].str.split('|').explode().unique()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_df.set_index('unique_values',inplace=True)\n",
    "full_df_filtered = full_df[~full_df.index.isin(distinct_df.index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_address(df):\n",
    "    json_addresses = []\n",
    "    unique_addresses = set()\n",
    "    for _, row in df.iterrows():\n",
    "        address = {\n",
    "            'id': row['identifier'],\n",
    "            'phone': row['phone_parsed'],\n",
    "            # 'country': row['country_code'],\n",
    "            'city': row['city'],\n",
    "            'zip_code': row['zip_code'],\n",
    "            'raw_address': row['address']\n",
    "        }\n",
    "        address_str = json.dumps(address)\n",
    "        if address_str not in unique_addresses:\n",
    "            json_addresses.append(address)\n",
    "            unique_addresses.add(address_str)\n",
    "        \n",
    "    return json.dumps(json_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = full_df.groupby(['company_name_norm','country_code','domain'])\\\n",
    "                     .apply(lambda df: pd.Series({\n",
    "                                          'rows_count': len(df),\n",
    "                                          'categories': '|'.join(df['category'].dropna().unique()),\n",
    "                                          'addresses': create_json_address(df)\n",
    "                                                        })).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.to_parquet('../../datasets/output/final_agg_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records                 : 419349    [100.00 %]\n",
      "Total records no country      :      0    [  0.0  %]\n",
      "Total records no domain       :      0    [  0.0  %]\n",
      "Total records no category     :  35565    [  8.48 %]\n",
      "Total records no address      :      0    [  0.0  %]\n"
     ]
    }
   ],
   "source": [
    "total_records = len(agg_data)\n",
    "null_country  = len(agg_data[agg_data['country_code']==''])\n",
    "null_domain  = len(agg_data[agg_data['domain']==''])\n",
    "null_category = len(agg_data[agg_data['categories']==''])\n",
    "null_address = len(agg_data[agg_data['addresses']==''])\n",
    "\n",
    "print(f'Total records                 : {total_records}    [100.00 %]')\n",
    "print(f'Total records no country      :      {null_country}    [  {round((null_country/total_records)*100,2)}  %]')\n",
    "print(f'Total records no domain       :      {null_domain}    [  {round((null_domain/total_records)*100,2)}  %]')\n",
    "print(f'Total records no category     :  {null_category}    [  {round((null_category/total_records)*100,2)} %]')\n",
    "print(f'Total records no address      :      {null_address}    [  {round((null_address/total_records)*100,2)}  %]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
